train_file:  ['data/finetune/icfg_train.json']
test_file: 'data/finetune/icfg_test.json'
image_root: '/HOME/xvlm/images/ICFG-PEDES/'

t: 1
dop: 0.95
LabelSmooth: 0.1


## Vision Encoder
# swin
use_swin: True
vision_config: 'configs/config_swinB_384.json'
image_res: 384
patch_size: 32

h: 384
w: 128


## Text Encoder
use_roberta: False
text_config: 'configs/config_bert.json'
text_encoder: 'data/bert-base-uncased'


## Training
batch_size_train: 120
batch_size_test: 150
batch_size_test_text: 750

max_tokens: 56
max_words: 56

embed_dim: 256
temp: 0.07
k_test: 128


## mlm loss
mlm: True
#mlm: False

mask_prob: 0.25
max_masks: 10
skipgram_prb: 0.2
skipgram_size: 3
mask_whole_word: True


## Other Settings
optimizer: {opt: adamW, lr: 1e-4, weight_decay: 0.01, lr_mult: 2}

#schedular: {sched: linear, lr: 1e-4, epochs: 100, num_warmup_steps: 0.1}
schedular: {sched: step, lr: 1e-4, epochs: 30, num_warmup_steps: 0.1}


pa100k: False
icfg_rstp: True

erasing_p: 0.6  # erasing_p: 0


lr_2: True
#lr_2: False

load_params: True
#load_params: False

#load_pretrained: True
load_pretrained: False

#pre: True #load 16m_base_model_state_step_199999.th
pre: False

eda: True
#eda: False
eda_p: 1
